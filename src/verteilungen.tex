\section{Diskrete Verteilungen}

\begin{definition}{Verteilungsfunktion}{vertf-disk}
Sei $X$ eine diskrete \link{def:zvar}{Zufallsvariable} mit Zustandsraum $x_0,
x_1, \ldots$. Die Funktion
\[
F_X:\R\to\R,\ F_X(z) = P(X \le z)
\]
heißt \defw{Verteilungsfunktion} der Zufallsvariable $X$. Die
Verteilungsfunktion eine Treppenfunktion, die an den Stellen $x_k$ um
$p_k = P(X=x_k)$ springt. Darum gilt:
\[
F_X(z) = \sum_{x_k\le z}P(X=x_k) = \sum_{x_k\le z} p_k
\]
\end{definition}

Eine Art Umkehrfunktion der Verteilungsfunktion ist die Quantilfunktion:
\begin{definition}{Quantilfunktion}{quantilf}
Sei $F_X(z) = P(X\le z)$ die Verteilungsfunktion einer diskreten Zufallsvariable
$X$. Dann heißt
\[
F_X^{-1}(z) = \mathrm{min}\{x\in\R: F(x) \ge z\},\quad z\in(0,1)
\]
die \defw{Quantilfunktion} von $X$.
\end{definition}

\medskip
Im Folgenden Abschnitt sei $X$ eine diskrete \link{def:zvar}{Zufallsvariable}
mit Zustandsraum $S$, $A \in S$ und $P$ eine
\link{def:verteilung}{Wahrscheinlichkeitsverteilung} dieser Zufallsvariable.


\subsection{Gleichverteilung}

Die Gleichverteilung ist eine sehr einfache Verteilung, bei der jeder Wert der
Zufallsvariable mit der gleichen Wahrscheinlichkeit auftritt:
\[
P(A) = \frac{|A|}{|S|}
\]

\subsection{Bernoulli-Verteilung ($B(p)$)}

Die Bernoulli-Verteilung beschreibt eine Zufallsvariable, die nur zwei mögliche
Zustände besitzt, hier bezeichnet als $S = \{0,1\}$. Der beliebig, aber fest
gewählte Ausgang $A$ besitzt die Wahrscheinlichkeit $0 \le p \le 1$, sodass
gilt:
\begin{align*}
P(X=1)&=p  \\
P(X=0)&=1-p
\end{align*}

\subsection{Binomialverteilung ($B(n,p)$)}

Die Binomialverteilung beschreibt die $n$-fache Durchführung eines Experiments
mit nur zwei komplementären Ausgängen werden. Die Zufallsvariable $X$ gibt an,
wie oft bei $n$-facher Wiederholung der beliebig, aber fest gewählte Ausgang $A$
eintritt. Damit kann $X$ die Werte $0, ..., n$ annehmen. Die Wahrscheinlichkeit
$p$ des Eintretens des gewählten Ausgangs bleibt dabei über alle $n$
Wiederholunge gleich. Es gilt:
\[
P(X=k) = \binom{n}{k}\cdot p^k\cdot(1-p)^{n-k}
\]

\subsection{Geometrische Verteilung ($Geo(p)$)}

Eine geometrische Verteilung entsteht durch die Wiederholung eines
Wahrscheinlichkeitsexperiments mit zwei komplementären Ausgängen. Die
Zufallsvariable $X$ beschreibt die Anzahl an Versuchen, die durchgeführt werden
müssen, bis der beliebig, aber fest gewählte Ausgang $B$ eintritt.

Der Zustandsraum von $X$ ist damit $\N_0$. Sei $p$ die Wahrscheinlichkeit, dass
Ausgang $B$ eintritt. Die Wahrscheinlichkeit, dass nach $k$ Wiederholungen der
Ausgang $B$ das erste mal auftritt, ist:
\[
P(X=k) = (1-p)^k\cdot p
\]

\subsection{Poisson-Verteilung ($Poi(\lambda)$)}

Die Poisson-Verteilung entsteht bei Vorgängen, die im Durchschnitt mit
konstanter Rate $\lambda \in (0, \infty)$ in einem beliebigen, aber
festen Zeitintervall auftreten. Die Zufallsvariable $X$ beschreibt, wie viele
Vorgänge tatächlich in dem Zeitintervall aufgetreten sind. Es gilt:
\begin{align*}
P(X=k) &= \frac{\lambda^k}{k!}\cdot\e^{-\lambda} \\
\E(X) &= \lambda
\end{align*}

\section{Stetige Verteilungen}

\begin{definition}{Wahrscheinlichkeitsdichte}{dichte}
Sei $X$ eine stetige \link{def:zvar}{Zufallsvariable} mit Zustandsraum $S$.
Eine Funktion $\rho: \R \rightarrow \R$ heißt \defw{Wahrscheinlichkeitsdichte},
wenn gilt:
\begin{align*}
  \forall x: \rho(x) \ge 0 \\
  \int \rho(x) \,\mathrm{d}x = 1
\end{align*}
\end{definition}

Die Wahrscheinlichkeitsdichte kann verwendet werden, um die Wahrscheinlichkeit,
dass X bestimmte Werte annimmt, zu berechnen ($a,b\in\R$):
\begin{align*}
  P(X < b) &= \int_{-\infty}^{b}\rho(x)\,\mathrm{d}x\\
  P(a<X<b) &= \int_{a}^{b}\rho(x)\,\mathrm{d}x\\
  P(X < b) &= \int^{\infty}_{b}\rho(x)\,\mathrm{d}x
\end{align*}

\begin{definition}{Verteilungsfunktion}{vertf}
Sei $X$ eine \link{def:zvar}{Zufallsvariable}. Die Funktion
\[F_X:\R\to\R,\ F_X(z) = P(X \le z)\]
heißt \defw{Verteilungsfunktion} von $X$.
\end{definition}

Die Verteilungsfunktion ist monoton wachsend und rechtsstetig. Weiterhin gilt:
\begin{align*}
0\le F_X(z&)\le 1 \\
F(-\infty&) = 0 \\
F(\infty&) = 1
\end{align*}

Die Verteilungsfunktion $F_X$ kann wie folgt verwendet werden, um
Wahrscheinlichkeiten bezüglich der Zufallsvariable $X$ zu berechnen:
\begin{align*}
P(X>a) = &1 - F_X(a) \\
P(X\le b) = &F_X(b) \\
P(a < X \le b) = &F_X(b) - F_X(a)
\end{align*}

Im Folgenden Abschnitt sei $X$ eine stetige \link{def:zvar}{Zufallsvariable}
mit Zustandsraum $S$, $A \in S$ und $P$ eine
\link{def:verteilung}{Wahrscheinlichkeitsverteilung} dieser Zufallsvariable.


\subsection{Gleichverteilung ($U(a,b)$)}
\label{vert-gleich}

Die gleichverteilte Zufallsvariable $X$ nimmt die Werte $S=(a,b)$ an. Für die
Wahrscheinlichkeitsdichte gilt:
\[
\rho(x) = \frac{1}{b-a}\cdot\mathbb{I}_{(a,b)}(x)
\]
Dabei bezeichnet $\mathbb{I}_{(a,b)}$ die \defw{Indikatorfunktion}, die Werte im
Intervall von $(a,b)$ auf $1$ und alle anderen Werte auf $0$ abbildet.

\subsection{Exponentialverteilung ($Exp(\lambda)$)}
\label{vert-exp}

Für eine Exponentialverteilung mit konstanter Ereignisrate $\lambda>0$ gilt:
\begin{align*}
\rho(x) &= \lambda\cdot \e^{-\lambda x}\cdot\mathbb{I}_{(0, \infty)} \\
F(z) &= 1 - \e^{-\lambda\cdot z}
\end{align*}

\subsection{Normalverteilung ($N(\mu, \sigma^2)$)}

In der Natur kommen Normalverteilungen vor wenn sich eine große Anzahl
unabhängiger Verteilungen überlagern. Für die Wahrscheinlichkeitsdichte gilt:
\[
\rho(x) = \frac{1}{\sqrt{2\pi\sigma^2}}\cdot exp(-\frac{(x-\mu)^2}{2\sigma^2})
\]

\subsection{Standardnormalverteilung ($N(0,1)$)}
\label{vert-stdnormal}

Eine standardnormalverteilte Zufallsvariable nimmt im Mittel den Wert $0$ mit
einer Varianz von $1$ an. Es gilt:
\[
\rho(x) = \frac{1}{\sqrt{2\pi}}\cdot exp(-\frac{x^2}{2})
\]

Die \link{def:vertf}{Verteilungsfunktion} der Standardnormalverteilung wird mit $\Phi(z)$ bezeichnet.

Ist $X$ normalverteilt mit $\mu$ und $\sigma^2$, dann ist die Zufallsvariable
\[
Z=\frac{X-\mu}{\sigma}
\]

standardnormalverteilt.
