\newcommand{\stat}{\underline{\pi}} % stationäre Wahrscheinlichkeit

Dieser Abschnitt beschäftigt sich mit der \link{def:mk-vert}{Verteilung der
Markovkette} nach unendlich vielen Schritten.

\textbf{Achtung: Die hier verwendete
Notation weicht zum Teil deutlich von den Vorlesungsvideos ab.}

\begin{definition}{Stationäre Verteilung}{mk-stat}
Sei $(X)_{n\in N_0}$ eine Markovkette mit \link{def:mk-matr}{Übergangsmatrix}
$\Pi$ und endlichem Zustandsraum $S$. Dann heißt die
\link{def:mk-vert}{Verteilung} $\stat$ \defw{stationäre Verteilung},
wenn gilt:
\[
\stat\cdot\Pi = \stat
\]
\end{definition}

Gelangt oder startet man in einer stationären Verteilung, ändert sich die
Wahrscheinlichkeit, sich in einem Zustand zu befinden, nicht mehr.

\subsection{Ergodische Markovketten}

\begin{theorem}{Hauptsatz für ergodische Markovketten}{ergod}
Sei $(X)_{n\in N_0}$ eine \link{def:mk-ergod}{ergodische} Markovkette mit
\link{def:mk-matr}{Übergangsmatrix} $\Pi$ und $y$ ein Zustand der Markovkette
mit \link{def:mk-rueckk}{Rückkehrzeit} $T_y$. Dann
besitzt die Markovkette \emph{genau} eine stationäre Verteilung $\stat$
für die gilt:
\[
\lim_{n\to\infty}\Pi(X_n = y) = lim_{n\to\infty}\Pi^n(x, y) = \stat(y)
\]
Weiterhin existiert ein Zusammenhang zwischen der erwarteten Rückkehrzeit und
der stationären Verteilung:
\[
\stat(y) = \frac{1}{\E(T_y|X_0=y)}
\]
\end{theorem}

Je weiter eine ergodische Markovkette läuft, desto mehr nähert sich die
Wahrscheinlichkeitsverteilung an die stationäre Verteilung an. Die stationäre
Verteilung gibt – zumindest auf lange Sicht – an, mit welcher Wahrscheinlichkeit
man sich in den jeweiligen Zuständen befindet.

Die stationäre Verteilung einer ergodischen Markovkette kann berechnet
werden. Dafür nutzt man die Tatsache, dass die stationäre Verteilung (per
Definition) ein Eigenvektor\more{mfnf-ew-ev} der Übergangsmatrix. Zusätzlich
muss wird eine Gleichung eingefügt, die die Normierung der stationären
Verteilung auf 1 sicherstellt. Es ergibt sich folgendes
lineares Gleichungssystem:
\begin{equation}\label{eq:stat-lgs}
\begin{pmatrix}
\Pi_{00}-1 & \Pi_{10} & \ldots & \Pi_{j0} \\
\Pi_{01} & \Pi_{11}-1 &        & \Pi_{j1} \\
\vdots   &            & \ddots & \vdots \\
\Pi_{0i} & \Pi_{1i} & \ldots &   \Pi_{ji}-1 \\
    1    &     1    & \ldots &   1
\end{pmatrix}\cdot \vec{\stat} = \begin{pmatrix}0\\0\\\vdots\\0\\1\end{pmatrix}
\end{equation}
Wichtig ist auch, dass die Matrix $\Pi$ transponiert aufgeschrieben, da eine
Spalte der Matrix einer Gleichung entspricht.

\subsection{Nichtergodische Markovketten}

\newcommand{\lzv}{\Pi^\infty} % Langzeitverhalten

Das Langzeitverhalten von nichtergodischen Markovketten hängt von Startzustand
ab. Es wird in der Matrix $\lzv$ zusammengefasst, die jedem Startzustand die auf
lange Sicht zu erwartende Verteilung zuordnet. Die Regeln zur Bestimmung des
Langzeitverhaltens unterscheiden sich je nach dem ob der Startzustand in
einer \link{def:mk-abg}{abgeschlossenen} oder \link{def:mk-trans}{transienten}
Klasse liegt.

\medskip
Im Folgenden sei $(X)_{n\in N_0}$ eine Markovkette mit endlichem Zustandsram $S$
und \link{def:mk-matr}{Übergangsmatrix} $\Pi$.

Das Langzeitverhalten bei Start in einem Zustand einer
\link{def:mk-abg}{abgeschlossenen} Klasse $C$ entspricht der
\link{def:mk-stat}{stationäre Verteilung} $\stat^{(C)}$ der auf die Zustände in
$C$ beschränkten Markovkette (siehe \eqref{eq:stat-lgs}). Der Übergang in einen
Zustand außerhalb der Klasse $C$ ist ausgeschlossen. Für $x, x' \in C$ und
$y\notin C$ gilt:
\begin{align}\label{eq:lzv-abg-abg}
  \lzv(x,x') &= \stat^{(C)}(x') \\
  \label{eq:lzv-abg-x}
  \lzv(x,y) &= 0
\end{align}

\medskip

Da \link{def:mk-trans}{transiente} Klassen nur verlassen, aber nicht in sie
zurückgekehrt werden kann, ist die langfristige Wahrscheinlichkeit, sich in
einem transienten Zustand zu befinden, null. Die Wahrscheinlichkeit, bei Start
in einem transienten Zustand $t$ langfristig in die abgeschlossene Klasse $C$
überzugehen, wird mit $p_{t\to C}$ bezeichnet \warn{andere Schreibweise als in
der Vorlesung}. Diese sogenannte Absorptionswahrscheinlichkeit verteilt sich
dann innerhalb von $C$ gemäß der berechneten stationären Verteilung.

Seien $x,x'$ transiente Zustände und $y$ Zustand einer
abgeschlossenen Klasse $C$. Dann gilt:
\begin{align}
  \label{eq:lzv-trans-abg}
  \lzv(x,y) &= p_{t\to C}\cdot\stat^{(C)}(y) \\
  \label{eq:lzv-trans-trans}
  \lzv(x,x') &= 0
\end{align}

Die Absorptionswahrscheinlichkeiten von Zuständen einer transienter Klasse $T$
bezüglich des Übergangs in die abgeschlossene Klasse $C$ bilden ein
lineares Gleichungssystem. Jede Gleichung für $t\in T$ ergibt sich
aus der Wahrscheinlichkeit des direkten Überangs in $C$ und der
Wahrscheinlichkeit, indirekt über die anderen Zustände von $T$ in $C$
überzugehen:
\[
p_{t\to C} = \sum_{c\in C} \Pi(t,c) + \sum_{t'\in T}\Pi(t,t')\cdot p_{t'\to C}
\]

\begin{example}{Langzeitverhalten einer nichtergodischen Markovkette}{mk-lzv-nerg}
Gegeben sei folgende Markovkette:

\begin{minipage}{0.45\textwidth}
  \begin{tikzpicture}
    \node[v] (1) at (0,1.5) {1};
    \node[v] (2) at (-1.5,0) {2};
    \node[v] (3) at (0,0) {3};
    \node[v] (4) at (1.5,0) {4};

    \draw[e] (1) to[loop above] ();
    \draw[e] (2) to[loop below] ();
    \draw[e] (3) to[loop below] ();
    \draw[e] (4) to[loop below] ();
    \draw[e] (1) -- (2);
    \draw[e] (1) -- (3);
    \draw[e] (1) -- (4);
    \draw[e] (2) to[bend left] (3);
    \draw[e] (3) to[bend left] (2);
  \end{tikzpicture}
\end{minipage}
\begin{minipage}{0.45\textwidth}
  \[\Pi = \begin{pmatrix}
    0.1 & 0.4 & 0.3 & 0.2 \\
     0  & 0.2 & 0.8 &  0  \\
     0  & 0.9 & 0.1 &  0  \\
     0  &  0  &  0  &  1
  \end{pmatrix}\]
\end{minipage}

Die Markovkette ist nicht \link{def:mk-irred}{irreduzibel}, da mehr als eine
Klasse existiert ($S_{/\lr} = {S_1, S_{2,3}, S_{4}}$), Satz \ref{satz:ergod}
kann also nicht angewandt werden.

\medskip
Da Klasse $S_4$ abgeschlossen und Zustand 4 absorbierend ist, ergibt sich als
Sonderfall von \eqref{eq:lzv-abg-abg} und \eqref{eq:lzv-abg-x} folgende
Verteilung:
\[\begin{pmatrix}0 & 0 & 0 & 1\end{pmatrix}\]

Klasse $S_{2,3}$ ist abgeschlossen. Die stationäre Verteilung $\stat^{(S_{2,3})}$
ergibt sich als Lösung des Gleichungssystems (Vergleiche \eqref{eq:stat-lgs})
und bestimmt $\lzv(2..3, 2..3)$:
\[
\begin{pmatrix}
0.2 -1 & 0.9     \\
0.8    & 0.1 - 1 \\
   1   &  1
\end{pmatrix}\cdot \vec{\stat}^{(S_{2,3})} = \begin{pmatrix}0\\0\\1\end{pmatrix}
\iff \vec{\stat}^{(S_{2,3})} =
\renewcommand\arraystretch{1.3}
\begin{pmatrix}0.53\\0.47\end{pmatrix}
\]

Zustand 1 ist transient, damit gilt $\lzv(1,1) = 0$
(\eqref{eq:lzv-trans-trans}). Als Zwischenergebnis bestimmen wir die
Absorptionswahrscheinlichkeiten $p_{abs,1}(S_{2,3})$ und $p_{abs,1}(S_{4})$:
\begin{align*}
p_{abs,1}(S_{2,3}) &=&  0.4 + 0.3 + 0.1 \cdot p_{abs,1}(S_{2,3}) & \implies
p_{abs,1}(S_{2,3}) = \frac{0.7}{0.9} = 0.78  \\
p_{abs,1}(S_{4})   &=&  0.2 + 0.1 \cdot p_{abs,1}(S_4) &\implies
p_{abs,1}(S_4) =\frac{0.2}{0.9} = 0.22
\end{align*}
Durch Anwendung von Gleichung \eqref{eq:lzv-trans-abg} ergibt sich:
\begin{align*}
\lzv(1,2) &=& p_{abs,1}(S_{2,3}) &\cdot\stat^{(S_{2,3})}(2) &= 0.41 \\
\lzv(1,3) &=& p_{abs,1}(S_{2,3}) &\cdot\stat^{(S_{2,3})}(3) &= 0.37 \\
\lzv(1,4) &=& p_{abs,1}(S_4)     &\cdot\stat^{(S_4)}    (4) &= 0.22
\end{align*}
Damit sind alle Einträge der Matrix $\lzv$ bestimmt:
\[
\lzv = \begin{pmatrix}
   0  & 0.41 & 0.37 & 0.22 \\
   0  & 0.53 & 0.47 &  0   \\
   0  & 0.53 & 0.47 &  0   \\
   0  &  0   &  0   &  1
\end{pmatrix}
\]
Als Probe kann sichergestellt werden, dass die Matrix stochastisch ist, sich
also die Einträge jeder Zeile zu 1 summieren.
\end{example}

\subsection{Reversibilität}

\begin{definition}{Reversibilität; Detaillierte Balance}{mk-rev}
Sei $(X)_{n\in N_0}$ eine Markovkette mit Zustandsraum $S$, Übergangsmatrix
$\Pi$ und $\pi$ eine \link{def:mk-vert}{Verteilung}. Die Markovkette heißt
\defw{reversibel}, wenn gilt:
\[
\forall x,y\in S:\ \pi(y)\cdot\Pi(y,x) = \pi(x)\cdot\Pi(x,y)
\]
Diese Bedingung wird auch als \defw{detaillierte Balance} bzw. als
\defw{detailliertes Gleichgewicht} bezeichnet.
\end{definition}

In einer reversiblen Markovkette kann also nicht unterschieden werden, ob der
Prozess vorwärts oder rückwärts abläuft.

\begin{theorem}{}{mk-db}
Sei $\pi$ eine Verteilung, die die Bedingung der detaillierten Balance
für eine Markovkette erfüllt. Dann ist $\pi$ eine
\link{def:mk-stat}{stationäre Verteilung}.
\end{theorem}

Reversibilität ist eine stärkere Bedinung als Stationarität, es gibt also
stationäre Verteilungen, die nicht die Bedingung der detaillierten Balance
erfüllen.

\begin{theorem}{Schnittprinzip}{mk-schnittp}
Sei $(X)_{n\in N_0}$ eine \link{def:mk-ergod}{ergodische} Markovkette. Ist der
\link{def:mk-igraph}{Interaktionsgraph} von $(X)$ linear, das jeder Schnitt
zwischen zwei verbundenen Zuständen zerlegt den Graph in zwei disjunkte und
unverbundene Teile, so ist die stationäre Verteilung immer reversibel.
\end{theorem}

Da wir wissen, dass eine ergodische Markovkette immer genau eine stationäre
Verteilung besitzt (Satz \ref{satz:ergod}), folgt aus dem Schnittprinzip, dass
diese Verteilung auch reversibel ist. Dann können wir für die Verteilung die
detaillierten Balance annehmen. Das ist besonders hilfreich, wenn der
betrachtete Prozess sehr viele Zustände besitzt und die stationäre Verteilung
aufwändig zu berechnen ist.

\begin{example}{Warteschlange}{}
Ein bestimmter Server kann bis zu 100 Anfragen parallel bearbeiten. Pro Sekunde
erhält der Server mit Wahrscheinlichkeit $p^+ = 0.2$ eine neue Anfrage und schließt
mit Wahrscheinlichkeit $p^-=0.21$ eine Anfrage ab. Werden bereits 100 Anfragen
bearbeitet, werden neue Anfragen abgewiesen.

\emph{Wie hoch ist die Wahrscheinlichkeit, dass ein ankommender Auftrag abgewiesen
wird? Wie hoch ist die Wahrscheinlichkeit, dass die Maschine leerläuft?}

Die Anzahl der aktiven Anfragen kann durch eine Markovkette mit Zustandsraum
$S=\{0, 1,\ldots, 100\}$ beschrieben werden:

\medskip
\begin{tikzpicture}
  \node[v] (0) at (0,1) {0};
  \node[v] (1) at (2,1) {1};
  \node[v] (2) at (4,1) {2};
  \node[v] (n) at (6, 1) {$\ldots$};
  \node[v] (99) at (8,1) {99};
  \node[v] (100) at (10,1) {100};

  \draw[e] (0) to[loop left] node[anchor=south] {$p^-$} ();
  \draw[e] (100) to[loop right] node[anchor=south] {$p^+$} ();
  \draw[e] (0) to[bend left] node[anchor=south] {$p^+$} (1);
  \draw[e] (1) to[bend left] node[anchor=north] {$p^-$} (0);
  \draw[e] (1) to[bend left] node[anchor=south] {$p^+$} (2);
  \draw[e] (2) to[bend left] node[anchor=north] {$p^-$} (1);
  \draw[e] (2) to[bend left] node[anchor=south] {$p^+$} (n);
  \draw[e] (n) to[bend left] node[anchor=north] {$p^-$} (2);
  \draw[e] (n) to[bend left] node[anchor=south] {$p^+$} (99);
  \draw[e] (99) to[bend left] node[anchor=north] {$p^-$} (n);
  \draw[e] (99) to[bend left] node[anchor=south] {$p^+$} (100);
  \draw[e] (100) to[bend left] node[anchor=north] {$p^-$} (99);
\end{tikzpicture}

Die Markovkette besteht nur aus einer einzigen Klasse, ist daher abgeschlossen,
rekurrent und irreduzibel. Da die Zustände 0 und 100 Periode 1 besitzten, ist
die Markovkette aperiodisch. Folglich ist die Markovkette auch ergodisch, es
existiert also eine eindeutige stationäre Verteilung $\stat$.

Diese Verteilung ist wegen der 101 Zustände sehr aufwändig zu berechnen. Wir
können jedoch das Schnittprinzip (Satz \ref{satz:mk-schnittp}) anwenden, da der
Interaktionsgraph der Markovkette linear ist. Das bedeutet, dass für die
stationäre Wahrscheinlichkeit die Bedingung der detaillierten Balance gilt:
\begin{align*}
\forall x,y\in S:\ &\pi(y)\cdot\Pi(y,x) = \pi(x)\cdot\Pi(x,y) \\
\implies&\stat(i)\cdot p^+ = \stat(i+1)\cdot p^- \\
\implies&\stat(i+1) = \frac{p^+}{p^-}\cdot\stat(i) \\
\implies&\stat = (c, c\cdot\gamma,c\cdot\gamma^2,\ldots,
c\cdot\gamma^{100})^{\T},\ \gamma = \frac{p^+}{p^-}, c\in\R
\end{align*}
Da $\stat$ eine Verteilung ist, wissen wir dass die Einträge insgesamt 1
ergeben. Damit kann $c$ bestimmt werden:
\begin{align*}
1 &= \sum_{i=0}^{100}c\cdot\gamma^i = c \sum_{i=0}^{100}\gamma^i \\
\overset{\text{Geom. Summenformel}}{\iff} 1 &= c\cdot\frac{1-\gamma^{101}}{1-\gamma} \\
\implies \stat(i) &= c\cdot\gamma^i = \frac{1-\gamma}{1-\gamma^{101}}\cdot \gamma^i
\end{align*}

Die Wahrscheinlichkeit, dass ein ankommender Auftrag abgewiesen wird, ist
$\stat(100)=3.6\cdot10^{-4}$, der Server also bereits voll ausgelastet ist. Die
Wahrscheinlichkeit für Leerlauf ist $\stat(0) = 4.79\cdot10^{-2}$.
\end{example}
