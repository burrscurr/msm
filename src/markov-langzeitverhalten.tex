\newcommand{\stat}{\underline{\pi}} % stationäre Wahrscheinlichkeit

Dieser Abschnitt beschäftigt sich mit der \link{def:mk-vert}{Verteilung der
Markovkette} nach unendlich vielen Schritten.

\textbf{Achtung: Die hier verwendete
Notation weicht zum Teil deutlich von den Vorlesungsvideos ab.}

\begin{definition}{Stationäre Verteilung}{mk-stat}
Sei $(X)_{n\in N_0}$ eine Markovkette mit \link{def:mk-matr}{Übergangsmatrix}
$\Pi$ und endlichem Zustandsraum $S$. Dann heißt die
\link{def:mk-vert}{Verteilung} $\stat$ \defw{stationäre Verteilung},
wenn gilt:
\[
\stat\cdot\Pi = \stat
\]
\end{definition}

Gelangt oder startet man in einer stationären Verteilung, ändert sich die
Wahrscheinlichkeit, sich in einem Zustand zu befinden, nicht mehr.

\subsection{Ergodische Markovketten}

\begin{theorem}{Hauptsatz für ergodische Markovketten}{ergod}
Sei $(X)_{n\in N_0}$ eine \link{def:mk-ergod}{ergodische} Markovkette mit
\link{def:mk-matr}{Übergangsmatrix} $\Pi$ und $y$ ein Zustand der Markovkette
mit \link{def:mk-rueckk}{Rückkehrzeit} $T_y$. Dann
besitzt die Markovkette \emph{genau} eine stationäre Verteilung $\stat$
für die gilt:
\[
\lim_{n\to\infty}\Pi(X_n = y) = lim_{n\to\infty}\Pi^n(x, y) = \stat(y)
\]
Weiterhin existiert ein Zusammenhang zwischen der erwarteten Rückkehrzeit und
der stationären Verteilung:
\[
\stat(y) = \frac{1}{\E(T_y|X_0=y)}
\]
\end{theorem}

Je weiter eine ergodische Markovkette läuft, desto mehr nähert sich die
Wahrscheinlichkeitsverteilung an die stationäre Verteilung an. Die stationäre
Verteilung gibt – zumindest auf lange Sicht – an, mit welcher Wahrscheinlichkeit
man sich in den jeweiligen Zuständen befindet.

Die stationäre Verteilung einer ergodischen Markovkette kann berechnet
werden. Dafür nutzt man die Tatsache, dass die stationäre Verteilung (per
Definition) ein Eigenvektor\more{mfnf-ew-ev} der Übergangsmatrix. Zusätzlich
muss wird eine Gleichung eingefügt, die die Normierung der stationären
Verteilung auf 1 sicherstellt. Es ergibt sich folgendes
lineares Gleichungssystem:
\begin{equation}\label{eq:stat-lgs}
\begin{pmatrix}
\Pi_{00}-1 & \Pi_{10} & \ldots & \Pi_{j0} \\
\Pi_{01} & \Pi_{11}-1 &        & \Pi_{j1} \\
\vdots   &            & \ddots & \vdots \\
\Pi_{0i} & \Pi_{1i} & \ldots &   \Pi_{ji}-1 \\
    1    &     1    & \ldots &   1
\end{pmatrix}\cdot \vec{\stat} = \begin{pmatrix}0\\0\\\vdots\\0\\1\end{pmatrix}
\end{equation}
Wichtig ist auch, dass die Matrix $\Pi$ transponiert aufgeschrieben, da eine
Spalte der Matrix einer Gleichung entspricht.

\subsection{Nichtergodische Markovketten}

\newcommand{\lzv}{\Pi^\infty} % Langzeitverhalten

Bei Nichtergodischen Markovketten ist das Langzeitverhalten nicht so einfach
bestimmbar, da die stationäre Verteilung vom Startzustand abhängt. Das
Langzeitverhalten der Markovkette wird durch die Matrix $\lzv$ beschrieben,
die für jeden möglichen Startzustand die entsprechende Langzeitverteilung
angibt.

\medskip
Sei $(X)_{n\in N_0}$ eine Markovkette mit endlichem Zustandsram $S$ und
\link{def:mk-matr}{Übergangsmatrix} $\Pi$, wobei $T\subseteq S$ die Menge aller
\link{def:mk-trans}{transienten} Zustände ist. Es gelten die nachfolgende Regeln
zur Bestimmung des Langzeitverhaltens.

In einer \link{def:mk-abg}{abgeschlossenen} Klasse $C$ kann das
Langzeitverhalten als \link{def:mk-stat}{stationäre Verteilung}
$\stat^{(C)}$ der auf die Zustände in $C$ beschränkten Markovkette bestimmt
werden (vergleiche \eqref{eq:stat-lgs}):
\begin{equation}\label{eq:lzv-abg-abg}
  \forall x,y\in C: \lzv(x,y) = \stat^{(C)}(y)
\end{equation}
Da eine \link{def:mk-abg}{abgeschlossene} Klasse $C$ nicht
verlassen werden kann, gilt für $x\in C$ und $y \notin C$:
\begin{equation}\label{eq:lzv-abg-x}
  \lzv(x,y) = 0
\end{equation}
Damit ist das Langzeitverhalten der Startzustände in abgeschlossenen Klassen
bestimmt.

\medskip
Das Langzeitverhalten bei Start in einem \link{def:mk-trans}{transienten}
Zustand $t\in T$ muss die
Wahrscheinlichkeit der Absorption durch eine abgeschlossene Klasse $C$
berücksichtigt werden, die mit $p_{abs}(t,C)$ bezeichnet wird. Die
Absorptionswahrscheinlichkeit berechnet sich rekursiv als Wahrscheinlichkeit des
direkten Übergangs in die absorbierende Klasse plus die Wahrscheinlichkeit des
indirekten Übergangs mit einem zusätzlichen Schritt innerhalb der transienten
Klasse:
\[
p_{abs,t}(C) = \sum_{y\in C} \Pi(x,y) + \sum_{z\in T}\Pi(x,z)\cdot p_{abs,z} \\
\]
Für alle $t$ einer transienten Klasse entsteht so ein Gleichungssystem.

Die Wahrscheinlichkteit, bei Start in $t$ in $y\in S$ zu
enden, berechnet sich durch die Absorptionswahrscheinlichkeit verknüpft mit
der stationären Wahrscheinlichkeit $\stat^{(C)}$ innerhalb von $C$:
\begin{equation}\label{eq:lzv-trans-abg}
\lzv(x,y) = p_{abs,t}(C)\cdot\stat^{(C)}(y)
\end{equation}
Die Wahrscheinlichkeit, sich in einem \link{def:mk-trans}{transienten}
Zustand zu befinden, sinkt auf lange Sicht auf 0:
\begin{equation}\label{eq:lzv-trans-trans}
\forall x\in S, y\in T: \lzv(x, y) = 0
\end{equation}
Damit ist das Langzeitverhalten für den Start in einem transitiven Zustand
definiert.
Da in endlichen Markovketten alle abgeschlossenen Klassen rekurrent sind
\warn{Begründung bzw. Beweis fehlt}, sind
durch die obigen Definitionen das Langzeitverhalten bestimmt.

\begin{example}{Langzeitverhalten einer nichtergodischen Markovkette}{mk-lzv-nerg}
Gegeben sei folgende Markovkette:

\begin{minipage}{0.45\textwidth}
  \begin{tikzpicture}
    \node[v] (1) at (0,1.5) {1};
    \node[v] (2) at (-1.5,0) {2};
    \node[v] (3) at (0,0) {3};
    \node[v] (4) at (1.5,0) {4};

    \draw[e] (1) to[loop above] ();
    \draw[e] (2) to[loop below] ();
    \draw[e] (3) to[loop below] ();
    \draw[e] (4) to[loop below] ();
    \draw[e] (1) -- (2);
    \draw[e] (1) -- (3);
    \draw[e] (1) -- (4);
    \draw[e] (2) to[bend left] (3);
    \draw[e] (3) to[bend left] (2);
  \end{tikzpicture}
\end{minipage}
\begin{minipage}{0.45\textwidth}
  \[\Pi = \begin{pmatrix}
    0.1 & 0.4 & 0.3 & 0.2 \\
     0  & 0.2 & 0.8 &  0  \\
     0  & 0.9 & 0.1 &  0  \\
     0  &  0  &  0  &  1
  \end{pmatrix}\]
\end{minipage}

Die Markovkette ist nicht \link{def:mk-irred}{irreduzibel}, da mehr als eine
Klasse existiert ($S_{/\lr} = {S_1, S_{2,3}, S_{4}}$), Satz \ref{satz:ergod}
kann also nicht angewandt werden.

\medskip
Da Klasse $S_4$ abgeschlossen und Zustand 4 absorbierend ist, ergibt sich als
Sonderfall von \eqref{eq:lzv-abg-abg} und \eqref{eq:lzv-abg-x} folgende
Verteilung:
\[\begin{pmatrix}0 & 0 & 0 & 1\end{pmatrix}\]

Klasse $S_{2,3}$ ist abgeschlossen. Die stationäre Verteilung $\stat^{(S_{2,3})}$
ergibt sich als Lösung des Gleichungssystems (Vergleiche \eqref{eq:stat-lgs})
und bestimmt $\lzv(2..3, 2..3)$:
\[
\begin{pmatrix}
0.2 -1 & 0.9     \\
0.8    & 0.1 - 1 \\
   1   &  1
\end{pmatrix}\cdot \vec{\stat}^{(S_{2,3})} = \begin{pmatrix}0\\0\\1\end{pmatrix}
\iff \vec{\stat}^{(S_{2,3})} =
\renewcommand\arraystretch{1.3}
\begin{pmatrix}0.53\\0.47\end{pmatrix}
\]

Zustand 1 ist transient, damit gilt $\lzv(1,1) = 0$
(\eqref{eq:lzv-trans-trans}). Als Zwischenergebnis bestimmen wir die
Absorptionswahrscheinlichkeiten $p_{abs,1}(S_{2,3})$ und $p_{abs,1}(S_{4})$:
\begin{align*}
p_{abs,1}(S_{2,3}) &=&  0.4 + 0.3 + 0.1 \cdot p_{abs,1}(S_{2,3}) & \implies
p_{abs,1}(S_{2,3}) = \frac{0.7}{0.9} = 0.78  \\
p_{abs,1}(S_{4})   &=&  0.2 + 0.1 \cdot p_{abs,1}(S_4) &\implies
p_{abs,1}(S_4) =\frac{0.2}{0.9} = 0.22
\end{align*}
Durch Anwendung von Gleichung \eqref{eq:lzv-trans-abg} ergibt sich:
\begin{align*}
\lzv(1,2) &=& p_{abs,1}(S_{2,3}) &\cdot\stat^{(S_{2,3})}(2) &= 0.41 \\
\lzv(1,3) &=& p_{abs,1}(S_{2,3}) &\cdot\stat^{(S_{2,3})}(3) &= 0.37 \\
\lzv(1,4) &=& p_{abs,1}(S_4)     &\cdot\stat^{(S_4)}    (4) &= 0.22
\end{align*}
Damit sind alle Einträge der Matrix $\lzv$ bestimmt:
\[
\lzv = \begin{pmatrix}
   0  & 0.41 & 0.37 & 0.22 \\
   0  & 0.53 & 0.47 &  0   \\
   0  & 0.53 & 0.47 &  0   \\
   0  &  0   &  0   &  1
\end{pmatrix}
\]
Als Probe kann sichergestellt werden, dass die Matrix stochastisch ist, sich
also die Einträge jeder Zeile zu 1 summieren.
\end{example}

\subsection{Reversibilität}

\begin{definition}{Reversibilität; Detaillierte Balance}{mk-rev}
Sei $(X)_{n\in N_0}$ eine Markovkette mit Zustandsraum $S$, Übergangsmatrix
$\Pi$ und $\pi$ eine \link{def:mk-vert}{Verteilung}. Die Markovkette heißt
\defw{reversibel}, wenn gilt:
\[
\forall x,y\in S:\ \pi(y)\cdot\Pi(y,x) = \pi(x)\cdot\Pi(x,y)
\]
Diese Bedingung wird auch als \defw{detaillierte Balance} bzw. als
\defw{detailliertes Gleichgewicht} bezeichnet.
\end{definition}

In einer reversiblen Markovkette kann also nicht unterschieden werden, ob der
Prozess vorwärts oder rückwärts abläuft.

\begin{theorem}{}{mk-db}
Sei $\pi$ eine Verteilung, die die Bedingung der detaillierten Balance
für eine Markovkette erfüllt. Dann ist $\pi$ eine
\link{def:mk-stat}{stationäre Verteilung}.
\end{theorem}

Reversibilität ist eine stärkere Bedinung als Stationarität, es gibt also
stationäre Verteilungen, die nicht die Bedingung der detaillierten Balance
erfüllen.

\begin{theorem}{Schnittprinzip}{mk-schnittp}
Sei $(X)_{n\in N_0}$ eine \link{def:mk-ergod}{ergodische} Markovkette. Ist der
\link{def:mk-igraph}{Interaktionsgraph} von $(X)$ linear, das jeder Schnitt
zwischen zwei verbundenen Zuständen zerlegt den Graph in zwei disjunkte und
unverbundene Teile, so ist die stationäre Verteilung immer reversibel.
\end{theorem}

Da wir wissen, dass eine ergodische Markovkette immer genau eine stationäre
Verteilung besitzt (Satz \ref{satz:ergod}), folgt aus dem Schnittprinzip, dass
diese Verteilung auch reversibel ist. Dann können wir für die Verteilung die
detaillierten Balance annehmen. Das ist besonders hilfreich, wenn der
betrachtete Prozess sehr viele Zustände besitzt und die stationäre Verteilung
aufwändig zu berechnen ist.

\begin{example}{Warteschlange}{}
Ein bestimmter Server kann bis zu 100 Anfragen parallel bearbeiten. Pro Sekunde
erhält der Server mit Wahrscheinlichkeit $p^+ = 0.2$ eine neue Anfrage und schließt
mit Wahrscheinlichkeit $p^-=0.21$ eine Anfrage ab. Werden bereits 100 Anfragen
bearbeitet, werden neue Anfragen abgewiesen.

\emph{Wie hoch ist die Wahrscheinlichkeit, dass ein ankommender Auftrag abgewiesen
wird? Wie hoch ist die Wahrscheinlichkeit, dass die Maschine leerläuft?}

Die Anzahl der aktiven Anfragen kann durch eine Markovkette mit Zustandsraum
$S=\{0, 1,\ldots, 100\}$ beschrieben werden:

\medskip
\begin{tikzpicture}
  \node[v] (0) at (0,1) {0};
  \node[v] (1) at (2,1) {1};
  \node[v] (2) at (4,1) {2};
  \node[v] (n) at (6, 1) {$\ldots$};
  \node[v] (99) at (8,1) {99};
  \node[v] (100) at (10,1) {100};

  \draw[e] (0) to[loop left] node[anchor=south] {$p^-$} ();
  \draw[e] (100) to[loop right] node[anchor=south] {$p^+$} ();
  \draw[e] (0) to[bend left] node[anchor=south] {$p^+$} (1);
  \draw[e] (1) to[bend left] node[anchor=north] {$p^-$} (0);
  \draw[e] (1) to[bend left] node[anchor=south] {$p^+$} (2);
  \draw[e] (2) to[bend left] node[anchor=north] {$p^-$} (1);
  \draw[e] (2) to[bend left] node[anchor=south] {$p^+$} (n);
  \draw[e] (n) to[bend left] node[anchor=north] {$p^-$} (2);
  \draw[e] (n) to[bend left] node[anchor=south] {$p^+$} (99);
  \draw[e] (99) to[bend left] node[anchor=north] {$p^-$} (n);
  \draw[e] (99) to[bend left] node[anchor=south] {$p^+$} (100);
  \draw[e] (100) to[bend left] node[anchor=north] {$p^-$} (99);
\end{tikzpicture}

Die Markovkette besteht nur aus einer einzigen Klasse, ist daher abgeschlossen,
rekurrent und irreduzibel. Da die Zustände 0 und 100 Periode 1 besitzten, ist
die Markovkette aperiodisch. Folglich ist die Markovkette auch ergodisch, es
existiert also eine eindeutige stationäre Verteilung $\stat$.

Diese Verteilung ist wegen der 101 Zustände sehr aufwändig zu berechnen. Wir
können jedoch das Schnittprinzip (Satz \ref{satz:mk-schnittp}) anwenden, da der
Interaktionsgraph der Markovkette linear ist. Das bedeutet, dass für die
stationäre Wahrscheinlichkeit die Bedingung der detaillierten Balance gilt:
\begin{align*}
\forall x,y\in S:\ &\pi(y)\cdot\Pi(y,x) = \pi(x)\cdot\Pi(x,y) \\
\implies&\stat(i)\cdot p^+ = \stat(i+1)\cdot p^- \\
\implies&\stat(i+1) = \frac{p^+}{p^-}\cdot\stat(i) \\
\implies&\stat = (c, c\cdot\gamma,c\cdot\gamma^2,\ldots,
c\cdot\gamma^{100})^{\T},\ \gamma = \frac{p^+}{p^-}, c\in\R
\end{align*}
Da $\stat$ eine Verteilung ist, wissen wir dass die Einträge insgesamt 1
ergeben. Damit kann $c$ bestimmt werden:
\begin{align*}
1 &= \sum_{i=0}^{100}c\cdot\gamma^i = c \sum_{i=0}^{100}\gamma^i \\
\overset{\text{Geom. Summenformel}}{\iff} 1 &= c\cdot\frac{1-\gamma^{101}}{1-\gamma} \\
\implies \stat(i) &= c\cdot\gamma^i = \frac{1-\gamma}{1-\gamma^{101}}\cdot \gamma^i
\end{align*}

Die Wahrscheinlichkeit, dass ein ankommender Auftrag abgewiesen wird, ist
$\stat(100)=3.6\cdot10^{-4}$, der Server also bereits voll ausgelastet ist. Die
Wahrscheinlichkeit für Leerlauf ist $\stat(0) = 4.79\cdot10^{-2}$.
\end{example}
